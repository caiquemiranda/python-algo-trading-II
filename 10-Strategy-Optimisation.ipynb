{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "# train_test_split.py\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import datetime\n",
    "import sklearn\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.lda import LDA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.qda import QDA\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from create_lagged_series import create_lagged_series\n",
    "\n",
    "# The test data is split into two parts: Before and after 1st Jan 2005.\n",
    "start_test = datetime.datetime(2005,1,1)\n",
    "\n",
    "# Create training and test sets\n",
    "X_train = X[X.index < start_test]\n",
    "X_test = X[X.index >= start_test]\n",
    "y_train = y[y.index < start_test]\n",
    "y_test = y[y.index >= start_test]\n",
    "\n",
    "\n",
    "# train_test_split.py\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a lagged series of the S&P500 US stock market index\n",
    "    snpret = create_lagged_series(\n",
    "    \"^GSPC\", datetime.datetime(2001,1,10),\n",
    "    datetime.datetime(2005,12,31), lags=5\n",
    "    )\n",
    "    # Use the prior two days of returns as predictor\n",
    "    # values, with direction as the response\n",
    "    X = snpret[[\"Lag1\",\"Lag2\"]]\n",
    "    y = snpret[\"Direction\"]\n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.8, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Create the (parametrised) models\n",
    "    print(\"Hit Rates/Confusion Matrices:\\n\")\n",
    "    models = [(\"LR\", LogisticRegression()),\n",
    "              (\"LDA\", LDA()),\n",
    "              (\"QDA\", QDA()),\n",
    "              (\"LSVC\", LinearSVC()),\n",
    "              (\"RSVM\", SVC(C = 1000000.0, \n",
    "                           cache_size = 200,\n",
    "                           class_weight = None,\n",
    "                           coef0 = 0.0, \n",
    "                           degree = 3, \n",
    "                           gamma = 0.0001,\n",
    "                           kernel = 'rbf',\n",
    "                           max_iter =- 1,\n",
    "                           probability = False,\n",
    "                           random_state = None,\n",
    "                           shrinking = True, \n",
    "                           tol = 0.001, \n",
    "                           verbose = False)),\n",
    "              (\"RF\", RandomForestClassifier(n_estimators = 1000, \n",
    "                                            criterion = 'gini',\n",
    "                                            max_depth = None,\n",
    "                                            min_samples_split = 2,\n",
    "                                            min_samples_leaf = 1,\n",
    "                                            max_features = 'auto',\n",
    "                                            bootstrap = True,\n",
    "                                            oob_score = False, \n",
    "                                            n_jobs = 1,\n",
    "                                            random_state = None,\n",
    "                                            verbose = 0))]\n",
    "    \n",
    "# Iterate through the models\n",
    "for m in models:\n",
    "\n",
    "    # Train each of the models on the training set\n",
    "    m[1].fit(X_train, y_train)\n",
    "\n",
    "    # Make an array of predictions on the test set\n",
    "    pred = m[1].predict(X_test)\n",
    "\n",
    "    # Output the hit-rate and the confusion matrix for each model\n",
    "    print(\"%s:\\n%0.3f\" % (m[0], m[1].score(X_test, y_test)))\n",
    "    print(\"%s\\n\" % confusion_matrix(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "# k_fold_cross_val.py\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from create_lagged_series import create_lagged_series\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Create a lagged series of the S&P500 US stock market index\n",
    "    snpret = create_lagged_series(\"^GSPC\", \n",
    "                                  datetime.datetime(2001,1,10), \n",
    "                                  datetime.datetime(2005,12,31), \n",
    "                                  lags=5)\n",
    "    \n",
    "    # Use the prior two days of returns as predictor\n",
    "    # values, with direction as the response\n",
    "    X = snpret[[\"Lag1\",\"Lag2\"]]\n",
    "    y = snpret[\"Direction\"]\n",
    "    \n",
    "    # Create a k-fold cross validation object\n",
    "    kf = cross_validation.KFold(len(snpret),\n",
    "                                n_folds = 10,\n",
    "                                indices = False,\n",
    "                                shuffle = True,\n",
    "                                random_state = 42)\n",
    "    \n",
    "    # Use the kf object to create index arrays that\n",
    "    # state which elements have been retained for training\n",
    "    # and which elements have beenr retained for testing\n",
    "    # for each k-element iteration\n",
    "    for train_index, test_index in kf:\n",
    "        X_train = X.ix[X.index[train_index]]\n",
    "        X_test = X.ix[X.index[test_index]]\n",
    "        y_train = y.ix[y.index[train_index]]\n",
    "        y_test = y.ix[y.index[test_index]]\n",
    "        \n",
    "        # In this instance only use the\n",
    "        # Radial Support Vector Machine (SVM)\n",
    "        print(\"Hit Rate/Confusion Matrix:\")\n",
    "        model = SVC(C = 1000000.0, \n",
    "                    cache_size = 200,\n",
    "                    class_weight = None,\n",
    "                    coef0 = 0.0,\n",
    "                    degree = 3, \n",
    "                    gamma = 0.0001,\n",
    "                    kernel = 'rbf',\n",
    "                    max_iter =-1 ,\n",
    "                    probability = False,\n",
    "                    random_state = None,\n",
    "                    shrinking = True,\n",
    "                    tol = 0.001,\n",
    "                    verbose = False)\n",
    "        \n",
    "        # Train the model on the retained training data\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make an array of predictions on the test set\n",
    "        pred = model.predict(X_test)\n",
    "        \n",
    "        # Output the hit-rate and the confusion matrix for each model\n",
    "        print(\"%0.3f\" % model.score(X_test, y_test))\n",
    "        print(\"%s\\n\" % confusion_matrix(pred, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "74af3d2f25f1e46ebd2903d59225d79e4675ec224d56c01fc30cd168c2010d53"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
