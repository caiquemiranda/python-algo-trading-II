{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Yahoo Finance and Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "                  Open        High         Low       Close   Adj Close  \\\n",
      "Date                                                                     \n",
      "2022-06-08  413.929993  415.820007  410.380005  411.220001  399.835297   \n",
      "2022-06-09  409.339996  411.739990  401.440002  401.440002  390.326080   \n",
      "2022-06-10  394.880005  395.779999  389.750000  389.799988  379.008301   \n",
      "2022-06-13  379.850006  381.809998  373.299988  375.000000  364.618073   \n",
      "2022-06-14  376.850006  377.940002  370.589996  373.869995  363.519318   \n",
      "\n",
      "               Volume  \n",
      "Date                   \n",
      "2022-06-08   64350000  \n",
      "2022-06-09   86289800  \n",
      "2022-06-10  132893900  \n",
      "2022-06-13  170004900  \n",
      "2022-06-14  104011800  \n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Define o ticker e o intervalo de datas\n",
    "ticker = \"SPY\"\n",
    "inicio = \"2010-02-01\"\n",
    "fim = \"2022-06-15\"\n",
    "\n",
    "# Baixa os dados do ticker selecionado\n",
    "dados = yf.download(ticker, start=inicio, end=fim)\n",
    "\n",
    "# Mostra os últimos registros\n",
    "print(dados.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "# quandl_data.py\n",
    "\n",
    "\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "def construct_futures_symbols(symbol, start_year=2010, end_year=2014):\n",
    "    \"\"\"\n",
    "    Constructs a list of futures contract codes\n",
    "    for a particular symbol and timeframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    futures = []\n",
    "    # March, June, September and\n",
    "    # December delivery codes\n",
    "    months = 'HMUZ'\n",
    "    for y in range(start_year, end_year+1):\n",
    "        for m in months:\n",
    "            futures.append(\"%s%s%s\" % (symbol, m, y))\n",
    "            \n",
    "    return futures\n",
    "\n",
    "\n",
    "def download_contract_from_quandl(contract, dl_dir):\n",
    "    \"\"\"\n",
    "    Download an individual futures contract from Quandl and then\n",
    "    store it to disk in the 'dl_dir' directory. An auth_token is\n",
    "    required, which is obtained from the Quandl upon sign-up.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Construct the API call from the contract and auth_token\n",
    "    api_call = \"http://www.quandl.com/api/v1/datasets/\"\n",
    "    api_call += \"OFDP/FUTURE_%s.csv\" % contract\n",
    "    # If you wish to add an auth token for more downloads, simply\n",
    "    # comment the following line and replace MY_AUTH_TOKEN with\n",
    "    # your auth token in the line below\n",
    "    params = \"?sort_order=asc\"\n",
    "    #params = \"?auth_token=MY_AUTH_TOKEN&sort_order=asc\"\n",
    "    full_url = \"%s%s\" % (api_call, params)\n",
    "    \n",
    "    # Download the data from Quandl\n",
    "    data = requests.get(full_url).text\n",
    "    \n",
    "    # Store the data to disk\n",
    "    fc = open('%s/%s.csv' % (dl_dir, contract), 'w')\n",
    "    fc.write(data)\n",
    "    fc.close()\n",
    "\n",
    "\n",
    "def download_historical_contracts(symbol, dl_dir, \n",
    "                                  start_year=2010, \n",
    "                                  end_year=2014):\n",
    "    \"\"\"\n",
    "    Downloads all futures contracts for a specified symbol\n",
    "    between a start_year and an end_year.\n",
    "    \"\"\"\n",
    "\n",
    "    contracts = construct_futures_symbols(symbol, start_year, end_year)\n",
    "\n",
    "    for c in contracts:\n",
    "        print(\"Downloading contract: %s\" % c)\n",
    "        download_contract_from_quandl(c, dl_dir)\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    symbol = 'ES'\n",
    "    \n",
    "    # Make sure you’ve created this\n",
    "    # relative directory beforehand\n",
    "    dl_dir = 'quandl/futures/ES'\n",
    "    \n",
    "    # Create the start and end years\n",
    "    start_year = 2010\n",
    "    end_year = 2014\n",
    "    \n",
    "    # Download the contracts into the directory\n",
    "    download_historical_contracts(symbol, \n",
    "                                  dl_dir, \n",
    "                                  start_year, \n",
    "                                  end_year)\n",
    "    \n",
    "    # Open up a single contract via read_csv\n",
    "    # and plot the settle price\n",
    "    es = pd.io.parsers.read_csv(\"%s/ESH2010.csv\" % dl_dir, index_col=\"Date\")\n",
    "    es[\"Settle\"].plot()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DTN IQFeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "# iqfeed.py\n",
    "\n",
    "\n",
    "import sys\n",
    "import socket\n",
    "\n",
    "\n",
    "def read_historical_data_socket(sock, recv_buffer=4096):\n",
    "    \"\"\"\n",
    "    Read the information from the socket, in a buffered\n",
    "    fashion, receiving only 4096 bytes at a time.\n",
    "    Parameters:\n",
    "    sock - The socket object\n",
    "    recv_buffer - Amount in bytes to receive per read\n",
    "    \"\"\"\n",
    "    \n",
    "    buffer = \"\"\n",
    "    data = \"\"\n",
    "    while True:\n",
    "        data = sock.recv(recv_buffer)\n",
    "        buffer += data\n",
    "        # Check if the end message string arrives\n",
    "        if \"!ENDMSG!\" in buffer:\n",
    "            break\n",
    "    \n",
    "    # Remove the end message string\n",
    "    buffer = buffer[:-12]\n",
    "    return buffer\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define server host, port and symbols to download\n",
    "    host = \"127.0.0.1\" # Localhost\n",
    "    port = 9100 # Historical data socket port\n",
    "    syms = [\"SPY\", \"IWM\"]\n",
    "\n",
    "# Download each symbol to disk\n",
    "for sym in syms:\n",
    "    print ('Downloading symbol: %s...') % sym\n",
    "    \n",
    "    # Construct the message needed by IQFeed to retrieve data\n",
    "    message = \"HIT,%s,60,20070101 075000,,,093000,160000,1\\n\" % sym\n",
    "    \n",
    "    # Open a streaming socket to the IQFeed server locally\n",
    "    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    sock.connect((host, port))\n",
    "    \n",
    "    # Send the historical data request\n",
    "    # message and buffer the data\n",
    "    sock.sendall(message)\n",
    "    data = read_historical_data_socket(sock)\n",
    "    sock.close\n",
    "    \n",
    "    # Remove all the endlines and line-ending\n",
    "    # comma delimiter from each record\n",
    "    data = \"\".join(data.split(\"\\r\"))\n",
    "    data = data.replace(\",\\n\",\"\\n\")[:-1]\n",
    "    \n",
    "    # Write the data stream to disk\n",
    "    f = open(\"%s.csv\" % sym, \"w\")\n",
    "    f.write(data)\n",
    "    f.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Financial Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install Quandl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "# cont_futures.py\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import Quandl\n",
    "\n",
    "def futures_rollover_weights(start_date, expiry_dates,contracts, rollover_days = 5):\n",
    "    \"\"\"\n",
    "    This constructs a pandas DataFrame that contains weights\n",
    "    (between 0.0 and 1.0) of contract positions to hold in order to\n",
    "    carry out a rollover of rollover_days prior to the expiration of\n",
    "    the earliest contract. The matrix can then be ’multiplied’ with\n",
    "    another DataFrame containing the settle prices of each\n",
    "    contract in order to produce a continuous time series\n",
    "    futures contract.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Construct a sequence of dates beginning\n",
    "    # from the earliest contract start date to the end\n",
    "    # date of the final contract\n",
    "    dates = pd.date_range(start_date, expiry_dates[-1], freq='B')\n",
    "    \n",
    "    # Create the ’roll weights’ DataFrame that will store the multipliers for\n",
    "    # each contract (between 0.0 and 1.0)\n",
    "    roll_weights = pd.DataFrame(np.zeros((len(dates), \n",
    "                                          len(contracts))),\n",
    "                                index=dates, columns=contracts)\n",
    "    \n",
    "    prev_date = roll_weights.index[0]\n",
    "    \n",
    "    # Loop through each contract and create the specific weightings for\n",
    "    # each contract depending upon the settlement date and rollover_days\n",
    "    for i, (item, ex_date) in enumerate(expiry_dates.iteritems()):\n",
    "        if i < len(expiry_dates) - 1:\n",
    "            roll_weights.ix[prev_date:ex_date - pd.offsets.BDay(), item] = 1\n",
    "            roll_rng = pd.date_range(end = ex_date - pd.offsets.BDay(),\n",
    "                                     periods = rollover_days + 1, freq='B')\n",
    "            \n",
    "            # Create a sequence of roll weights (i.e. [0.0,0.2,...,0.8,1.0]\n",
    "            # and use these to adjust the weightings of each future\n",
    "            decay_weights = np.linspace(0, 1, rollover_days + 1)\n",
    "            roll_weights.ix[roll_rng, item] = 1 - decay_weights\n",
    "            roll_weights.ix[roll_rng,\n",
    "                            expiry_dates.index[i+1]] = decay_weights\n",
    "        else:\n",
    "            roll_weights.ix[prev_date:, item] = 1\n",
    "        \n",
    "        prev_date = ex_date\n",
    "    \n",
    "    return roll_weights\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Download the current Front and Back (near and far) futures contracts\n",
    "    # for WTI Crude, traded on NYMEX, from Quandl.com. You will need to\n",
    "    # adjust the contracts to reflect your current near/far contracts\n",
    "    # depending upon the point at which you read this!\n",
    "    wti_near = Quandl.get(\"OFDP/FUTURE_CLF2014\")\n",
    "    wti_far = Quandl.get(\"OFDP/FUTURE_CLG2014\")\n",
    "    wti = pd.DataFrame({'CLF2014': wti_near['Settle'],\n",
    "                        'CLG2014': wti_far['Settle']},\n",
    "                        index = wti_far.index)\n",
    "    \n",
    "    \n",
    "    # Create the dictionary of expiry dates for each contract\n",
    "    expiry_dates = pd.Series({'CLF2014': datetime.datetime(2013, 12, 19),\n",
    "                            'CLG2014': datetime.datetime(2014, 2, 21)}).order()\n",
    "    \n",
    "    # Obtain the rollover weighting matrix/DataFrame\n",
    "    weights = futures_rollover_weights(wti_near.index[0],\n",
    "                                       expiry_dates, wti.columns)\n",
    "\n",
    "    # Construct the continuous future of the WTI CL contracts\n",
    "    wti_cts = (wti * weights).sum(1).dropna()\n",
    "    # Output the merged serie"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "74af3d2f25f1e46ebd2903d59225d79e4675ec224d56c01fc30cd168c2010d53"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
